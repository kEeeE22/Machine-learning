{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9FCOuAl7QM7S",
        "C2xawiPsHa95"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osNcswEEa_3s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###A"
      ],
      "metadata": {
        "id": "cax8Blp_PoVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Read Data for A\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8u9s6sNWKBC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read(data, label):\n",
        "  mp = {' ': 0, '+': 1, '#': 1}\n",
        "  X = []\n",
        "  with open(data, 'r') as file:\n",
        "\n",
        "    while True:\n",
        "      img = []\n",
        "\n",
        "      for _ in range(28):\n",
        "        line = file.readline()\n",
        "\n",
        "        if not line:\n",
        "          break\n",
        "\n",
        "        row = [mp[c] for c in line if c != '\\n']\n",
        "        img.append(row)\n",
        "\n",
        "      if not line:\n",
        "        break\n",
        "      while len(img) != 28:\n",
        "        img.append([0] * 28)\n",
        "      X.append(img)\n",
        "\n",
        "    file.close()\n",
        "\n",
        "  with open(label, 'r') as file:\n",
        "    y = [int(line) for line in file]\n",
        "    file.close()\n",
        "\n",
        "\n",
        "  y = np.array(y)\n",
        "  X = np.array(X)\n",
        "\n",
        "  return X, y\n",
        "\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "  return np.sum(y_true == y_pred) / len(y_true)"
      ],
      "metadata": {
        "id": "AV9qTgagFqeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = read('/content/trainingimages', '/content/traininglabels')"
      ],
      "metadata": {
        "id": "uR16ZP2xFxXp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "c75eebb9-190f-46ac-972f-3e304ae05b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/trainingimages'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-22113b5e39c0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/trainingimages'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/traininglabels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-950be1aa46c9>\u001b[0m in \u001b[0;36mread\u001b[0;34m(data, label)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'+'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'#'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/trainingimages'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = read('/content/testimages', '/content/testlabels')"
      ],
      "metadata": {
        "id": "M8StgnBbHOV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####visualize"
      ],
      "metadata": {
        "id": "wcbjpFN8KHey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def view_with_matplotlib(X, idx):\n",
        "    \"\"\"\n",
        "    Hiển thị một hình ảnh trong mảng 3D X bằng matplotlib.\n",
        "    \"\"\"\n",
        "    plt.imshow(X[idx], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "BeN82v4G6Bg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "view_with_matplotlib(X_train, 0)"
      ],
      "metadata": {
        "id": "rQ90zsed6iqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####A: Multinomial Naive Bayes"
      ],
      "metadata": {
        "id": "yZuaoZUUKGLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultinomialNaiveBayes:\n",
        "    def __init__(self, k=1.0):\n",
        "        self.k = k  # Smoothing parameter\n",
        "        self.class_priors = None\n",
        "        self.feature_probs = None\n",
        "        self.classes = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit mô hình với dl X, y.\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape[0], X.shape[1] * X.shape[2]\n",
        "        self.classes = np.unique(y)\n",
        "        n_classes = len(self.classes)\n",
        "\n",
        "\n",
        "        self.class_priors = np.zeros(n_classes)\n",
        "        self.feature_probs = np.zeros((n_classes, n_features))\n",
        "\n",
        "        X_reshaped = X.reshape(n_samples, n_features)\n",
        "\n",
        "        for idx, c in enumerate(self.classes):\n",
        "            X_c = X_reshaped[y == c]\n",
        "            self.class_priors[idx] = X_c.shape[0] / n_samples\n",
        "            self.feature_probs[idx, :] = (X_c.sum(axis=0) + self.k) / (X_c.sum() + self.k * 2)\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        return np.array([self._predict_single(x) for x in X])\n",
        "\n",
        "    def _predict_single(self, x):\n",
        "        log_probs = []\n",
        "        for idx, c in enumerate(self.classes):\n",
        "            log_class_prior = np.log(self.class_priors[idx])\n",
        "            log_likelihood = np.sum(np.log(self.feature_probs[idx]) * x)\n",
        "            log_probs.append(log_class_prior + log_likelihood)\n",
        "            predicted = self.classes[np.argmax(log_probs)]\n",
        "        return predicted"
      ],
      "metadata": {
        "id": "KZMcz_Zrz-MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Find k"
      ],
      "metadata": {
        "id": "JXQeBLx0pHIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accs = []\n",
        "k_ = [0.1, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "for i in k_:\n",
        "  naive = MultinomialNaiveBayes(k=i)\n",
        "  naive.fit(X_train, y_train)\n",
        "  pred1 = naive.predict(x_test.reshape(1000,784))\n",
        "  accs.append(accuracy_fn(y_test, pred1))"
      ],
      "metadata": {
        "id": "TYz4X-FzpIxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accs"
      ],
      "metadata": {
        "id": "6T49UStnprXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Save model as a file"
      ],
      "metadata": {
        "id": "9EwuCJGvPjRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "naive = MultinomialNaiveBayes(k=0.1)\n",
        "naive.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "nrQ2eiPMF_hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(naive, '/content/naive1.pkl')"
      ],
      "metadata": {
        "id": "tcr2C_c9OzHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load model"
      ],
      "metadata": {
        "id": "30LvAsnWPv2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = joblib.load('/content/naive1.pkl')"
      ],
      "metadata": {
        "id": "CZRzOwbxO821"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Classify"
      ],
      "metadata": {
        "id": "_X-yJv9APzTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predx = model.predict(x_test.reshape(1000,784))\n",
        "print(accuracy_fn(y_test, predx))"
      ],
      "metadata": {
        "id": "UP_8ynjRPB57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Nhãn dự đoán của của mẫu x_test[1]\n",
        "x = model.predict(x_test[1].reshape(1,784))\n",
        "x"
      ],
      "metadata": {
        "id": "HnpQEcz77n_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Nhãn thật của mẫu được dự đoán\n",
        "print(y_test[1])\n",
        "view_with_matplotlib(x_test, 1)"
      ],
      "metadata": {
        "id": "TB4gLROc771u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Confusion matrix"
      ],
      "metadata": {
        "id": "jcLmL74NgJni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics(y_true, y_pred, average=\"macro\"):\n",
        "    # Lấy các lớp duy nhất\n",
        "    classes = np.unique(np.concatenate([y_true, y_pred]))\n",
        "    num_classes = len(classes)\n",
        "\n",
        "    #Tính accuracy\n",
        "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "\n",
        "    # Tính confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Tính Precision, Recall cho từng lớp\n",
        "    precision_per_class = []\n",
        "    recall_per_class = []\n",
        "    f1_per_class = []\n",
        "    support_per_class = []\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        tp = cm[i, i]\n",
        "        fp = cm[:, i].sum() - tp\n",
        "        fn = cm[i, :].sum() - tp\n",
        "        support = cm[i, :].sum()\n",
        "\n",
        "        precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
        "        recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
        "        f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
        "\n",
        "        precision_per_class.append(precision)\n",
        "        recall_per_class.append(recall)\n",
        "        f1_per_class.append(f1)\n",
        "        support_per_class.append(support)\n",
        "\n",
        "    if average == \"macro\":\n",
        "        precision = np.mean(precision_per_class)\n",
        "        recall = np.mean(recall_per_class)\n",
        "        f1_score = np.mean(f1_per_class)\n",
        "    elif average == \"weighted\":\n",
        "        total_support = np.sum(support_per_class)\n",
        "        precision = np.sum(np.array(precision_per_class) * np.array(support_per_class)) / total_support\n",
        "        recall = np.sum(np.array(recall_per_class) * np.array(support_per_class)) / total_support\n",
        "        f1_score = np.sum(np.array(f1_per_class) * np.array(support_per_class)) / total_support\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1_score\n",
        "    }\n"
      ],
      "metadata": {
        "id": "RkVnfUCKU-Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vẽ dạng ma trận\n",
        "def confusion_matrix(y_true, y_pred):\n",
        "  num_classes = len(np.unique(y_true))\n",
        "  confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
        "\n",
        "  for true_label, pred_label in zip(y_true, y_pred):\n",
        "    confusion_matrix[true_label, pred_label] += 1\n",
        "\n",
        "  return confusion_matrix\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "  return np.sum(y_true == y_pred) / len(y_true)\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, labels=None, normalize=False, cmap=plt.cm.Blues):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)  # Chuẩn hóa theo hàng\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title('Confusion Matrix', fontsize=16)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if labels is None:\n",
        "        labels = np.unique(y_true)\n",
        "    tick_marks = np.arange(len(labels))\n",
        "    plt.xticks(tick_marks, labels, fontsize=12)\n",
        "    plt.yticks(tick_marks, labels, fontsize=12)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], fmt),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=12)\n",
        "\n",
        "    plt.ylabel('True label', fontsize=14)\n",
        "    plt.xlabel('Predicted label', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.grid(False)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ua9lYFFjMzid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = metrics(y_test, predx)\n",
        "print(z)"
      ],
      "metadata": {
        "id": "XTA7zP9fWGFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion matrix\n",
        "plot_confusion_matrix(y_test, predx, normalize=True)"
      ],
      "metadata": {
        "id": "w0_-PR5xNNQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Extra credit"
      ],
      "metadata": {
        "id": "9FCOuAl7QM7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def majority_value(block):\n",
        "    \"\"\"Return the majority value from a 2x2 pixel block.\"\"\"\n",
        "    return mode(block, axis=None).mode[0]\n",
        "\n",
        "def extract_features(image):\n",
        "    \"\"\"Extract majority features from a 2D image using 2x2 pixel blocks.\"\"\"\n",
        "    # Get the dimensions of the image\n",
        "    height, width = image.shape\n",
        "    # Calculate the dimensions of the feature array\n",
        "    feature_height = height // 2\n",
        "    feature_width = width // 2\n",
        "\n",
        "    # Initialize the feature array\n",
        "    features = np.zeros((feature_height, feature_width), dtype=image.dtype)\n",
        "\n",
        "    # Iterate over the image with a step of 2\n",
        "    for i in range(0, height - 1, 2):\n",
        "        for j in range(0, width - 1, 2):\n",
        "            # Extract the 2x2 block\n",
        "            block = image[i:i+2, j:j+2]\n",
        "            # Calculate the majority value and store it\n",
        "            features[i//2, j//2] = majority_value(block)\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "7mPy4PqJQQLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def extract_features(X):\n",
        "#   num_images, height, width = X.shape\n",
        "#   features = np.zeros((num_images, 14, 14), dtype=int)\n",
        "\n",
        "#   for idx in range(num_images):\n",
        "#     for i in range(0, height, 2):\n",
        "#       for j in range(0, width, 2):\n",
        "#         block = X[idx, i:i+2, j:j+2]\n",
        "#         majority_value = Counter(block.flatten()).most_common(1)[0][0]\n",
        "#         features[idx, i // 2, j // 2] = majority_value\n",
        "\n",
        "#     return features"
      ],
      "metadata": {
        "id": "hI5Lkq3cdsTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###lib for compare A"
      ],
      "metadata": {
        "id": "C2xawiPsHa95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "a = MultinomialNB()\n",
        "a.fit(X_train.reshape(X_train.shape[0], -1), y_train)"
      ],
      "metadata": {
        "id": "Q-sv4ASHGHiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = a.predict(x_test.reshape(x_test.shape[0], -1))"
      ],
      "metadata": {
        "id": "V62r0R1bHW9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_fn(y_test, y_pred))"
      ],
      "metadata": {
        "id": "jj8NEsrwHahp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###B"
      ],
      "metadata": {
        "id": "Zy2t7cMjMGNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load Data for B"
      ],
      "metadata": {
        "id": "ywN614rXKkXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Mall_Customers.csv', index_col='CustomerID')\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "CcYRGOqtH1kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#{'Female': 1, 'Male': 2}\n",
        "def label_encoding(data):\n",
        "    data_array = np.array(data)\n",
        "\n",
        "    unique_labels, encoded_data = np.unique(data_array, return_inverse=True)\n",
        "    encoded_data += 1\n",
        "    label_dict = {label: idx + 1 for idx, label in enumerate(unique_labels)}\n",
        "\n",
        "    return encoded_data.tolist(), label_dict\n",
        "\n",
        "def standard_scaler(data):\n",
        "    means = [sum(column) / len(column) for column in zip(*data)]\n",
        "    std_devs = [(sum((x - mean) ** 2 for x in column) / len(column)) ** 0.5 for column, mean in zip(zip(*data), means)]\n",
        "\n",
        "    scaled_data = [[(x - mean) / std for x, mean, std in zip(row, means, std_devs)]for row in data]\n",
        "\n",
        "    return scaled_data"
      ],
      "metadata": {
        "id": "FwbOEttcA2b3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns = ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']\n",
        "scaled_data = standard_scaler(df[numeric_columns].values.tolist())\n",
        "\n",
        "categorical_columns = ['Gender']\n",
        "encoded, _= label_encoding(df[categorical_columns].values.flatten())\n",
        "encoded = np.array(encoded).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "XIG95RO7H2OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(np.concatenate([encoded,scaled_data], axis=1))"
      ],
      "metadata": {
        "id": "JtNZQMakH8e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####B: KMeans"
      ],
      "metadata": {
        "id": "DYz_o6_pJ7g1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(point1, point2):\n",
        "  return np.linalg.norm(np.array(point1) - np.array(point2))"
      ],
      "metadata": {
        "id": "Rs26XQ4ILZP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Kmeans:\n",
        "    def __init__(self, n_clusters=2, max_iters=100):\n",
        "\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iters = max_iters\n",
        "        self.centroids = None\n",
        "        self.labels = None\n",
        "    # def initialize_centroids_kmeanspp(self, data):\n",
        "    #   \"\"\"Khởi tạo các centroid theo thuật toán K-means++.\"\"\"\n",
        "    #   centroids = [data[np.random.randint(data.shape[0])]]\n",
        "\n",
        "    #   for _ in range(1, self.n_clusters):\n",
        "    #     #distances = np.array([min([np.linalg.norm(x - c) ** 2 for c in centroids]) for x in data])\n",
        "    #     distances = np.array([min([euclidean_distance(x, c) ** 2 for c in centroids]) for x in data])\n",
        "    #     probabilities = distances / distances.sum()\n",
        "    #     cumulative_probabilities = np.cumsum(probabilities)\n",
        "    #     r = np.random.rand()\n",
        "\n",
        "    #     for j, p in enumerate(cumulative_probabilities):\n",
        "    #         if r < p:\n",
        "    #             centroids.append(data[j])\n",
        "    #             break\n",
        "\n",
        "    #   self.centroids = np.array(centroids)\n",
        "\n",
        "    def initialize_centroids(self, data):\n",
        "        self.centroids = data[np.random.choice(range(data.shape[0]), self.n_clusters, replace=False)]\n",
        "\n",
        "    def assign_clusters(self, data):\n",
        "        clusters = []\n",
        "        for point in data:\n",
        "            distances = [euclidean_distance(point, centroid) for centroid in self.centroids]\n",
        "            cluster = distances.index(min(distances))\n",
        "            clusters.append(cluster)\n",
        "        return clusters\n",
        "\n",
        "    def update_centroids(self, data):\n",
        "        new_centroids = []\n",
        "        for i in range(self.n_clusters):\n",
        "            cluster_points = [data[j] for j in range(len(data)) if self.labels[j] == i]\n",
        "            if cluster_points:\n",
        "                new_centroid = np.mean(cluster_points, axis=0).tolist()\n",
        "            else:\n",
        "                new_centroid = [0] * len(data[0])\n",
        "            new_centroids.append(new_centroid)\n",
        "        return new_centroids\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, data):\n",
        "        self.initialize_centroids(data)\n",
        "        #self.initialize_centroids_kmeanspp(data)\n",
        "\n",
        "        for _ in range(self.max_iters):\n",
        "            self.labels = self.assign_clusters(data)\n",
        "            new_centroids = self.update_centroids(data)\n",
        "            if np.all(np.linalg.norm(np.array(new_centroids) - np.array(self.centroids), axis=1) < 1e-6):\n",
        "              break\n",
        "            self.centroids = new_centroids\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "    def predict(self, data):\n",
        "        return self.assign_clusters(data)"
      ],
      "metadata": {
        "id": "InJB0Lqs-DzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2. Run to find the optimal k"
      ],
      "metadata": {
        "id": "XCmjG437Ig4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_wcss(data, centroids):\n",
        "    labels = np.argmin(np.linalg.norm(data[:, np.newaxis] - centroids, axis=2), axis=1)\n",
        "    wcss = sum(np.sum((data[labels == i] - centroid) ** 2) for i, centroid in enumerate(centroids))\n",
        "\n",
        "    return wcss"
      ],
      "metadata": {
        "id": "KgOkW7htIWYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "k = 20\n",
        "for i in range(1,k):\n",
        "  kmeans_i = Kmeans(n_clusters=i)\n",
        "  kmeans_i.fit(x)\n",
        "\n",
        "  d2centroids = calculate_wcss(x, kmeans_i.centroids)\n",
        "\n",
        "  min_distance = np.min(d2centroids, axis=0)\n",
        "  loss = np.sum(min_distance)\n",
        "  losses.append(loss)"
      ],
      "metadata": {
        "id": "p3h4U3tJITe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, k), losses, marker='o', linestyle='-')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Wcss')"
      ],
      "metadata": {
        "id": "A1LOVFdzIVBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Run with optimal k = 5"
      ],
      "metadata": {
        "id": "bbQqU6l-Il9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Kmeans(n_clusters=5, max_iters=100)\n",
        "model.fit(x)"
      ],
      "metadata": {
        "id": "CVovy1xhIYTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Visualize k mean clustering result"
      ],
      "metadata": {
        "id": "b6elxefmIwbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(x, columns=['Gender', 'Age', 'Annual Income (k$)', 'Spending Score (1-100)'])\n",
        "df['Cluster'] = model.labels\n",
        "\n",
        "sns.pairplot(df, hue='Cluster', palette='viridis')\n",
        "plt.suptitle('Pairplot of Data with Clusters', y=1.02)"
      ],
      "metadata": {
        "id": "pkzbnqGUI0lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(df,x=df['Annual Income (k$)'], y =df['Spending Score (1-100)'], hue='Gender',palette='viridis', legend='full')\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Wi23jKjar7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DrU4rRU3a3z6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}